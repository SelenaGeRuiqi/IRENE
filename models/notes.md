IRENE:
åŸºäºTransformerçš„ã€ç»Ÿä¸€å¤„ç†å¤šæ¨¡æ€åŒ»ç–—æ•°æ®çš„è¯Šæ–­æ¨¡å‹ ã€‚
å°†å½±åƒã€ä¸»è¯‰ã€åŒ–éªŒå•ç­‰å¤šç§ä¿¡æ¯ç»Ÿä¸€è¾“å…¥åˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œè¿›è¡Œç«¯åˆ°ç«¯çš„è¯Šæ–­ï¼Œè€Œä¸æ˜¯â€˜å…ˆæå–ç‰¹å¾å†èåˆ(æ—©/æ™šæœŸèåˆ)çš„ä¼ ç»Ÿæ–¹æ³• 

1. embedding [â†’](embed.py)
image: 16*16 --> CNN --> 1*1 patch
text: cc, lab, sex, age --> linear

2. encoder [â†’](encoder.py) block [â†’](block.py)
Unified Transformer:
    æ¨¡å¼1 - æ ‡å‡†æ¨¡å¼ï¼ˆmm=Falseï¼‰ï¼š
    - å¤„ç†å•ä¸€çš„èåˆååºåˆ—
    - ç±»ä¼¼æ ‡å‡†Transformer Blockçš„è¡Œä¸º
    - ç”¨äºæ¨¡æ€èåˆåçš„å±‚
    
    æ¨¡å¼2 - å¤šæ¨¡æ€æ¨¡å¼ï¼ˆmm=Trueï¼‰ï¼š
    - åŒæ—¶å¤„ç†å›¾åƒå’Œæ–‡æœ¬ä¸¤ä¸ªç‹¬ç«‹åºåˆ—
    - æ¯ä¸ªæ¨¡æ€æœ‰ç‹¬ç«‹çš„å½’ä¸€åŒ–å±‚å’ŒMLP
    - ä¿æŒæ¨¡æ€ç‰¹å¼‚æ€§ï¼Œç”¨äºæ—©æœŸå±‚

    1. å±‚0-1ï¼šåˆ†ç¦»å¤„ç†é˜¶æ®µï¼Œå›¾åƒå’Œæ–‡æœ¬å„è‡ªè¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—
    2. å±‚2ï¼šèåˆé˜¶æ®µï¼Œ å°†å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾åœ¨åºåˆ—ç»´åº¦æ‹¼æ¥
    3. å±‚3-11ï¼šç»Ÿä¸€å¤„ç†é˜¶æ®µï¼Œå¯¹èåˆåºåˆ—è¿›è¡Œæ ‡å‡†Transformerå¤„ç†

å®ç°ï¼šattn [â†’](attention.py)
if mm: å¤šæ¨¡æ€æ¨¡å¼, ä¸ºæ–‡æœ¬æ¨¡æ€åˆ›å»ºç‹¬ç«‹çš„Qã€Kã€VæŠ•å½±
    é¢å¤–åˆ›å»ºä¸€å¥—ä¸“é—¨ç”¨äºæ–‡æœ¬æ¨¡æ€çš„query_text, key_text, value_textçº¿æ€§å±‚ã€‚åŒæ—¶ï¼Œè¿˜ä¼šåˆ›å»ºé¢å¤–çš„Dropoutå±‚ï¼Œå¦‚attn_dropout_it (image-to-text) å’Œ attn_dropout_ti (text-to-image)ï¼Œç”¨äºè·¨æ¨¡æ€æ³¨æ„åŠ›çš„æ­£åˆ™åŒ–ã€‚
else: æ ‡å‡†æ¨¡å¼, ä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›è®¡ç®— 
    (1) text is not None: åœ¨å‰ä¸¤ä¸ªblockåˆ†åˆ«å¤„ç†å›¾åƒå’Œæ–‡æœ¬
        åˆ†åˆ«ç”Ÿæˆå›¾åƒå’Œæ–‡æœ¬çš„KQVï¼Œè®¡ç®—æ–‡æ–‡ï¼Œå›¾å›¾çš„self attnï¼Œå’Œæ–‡å›¾ï¼Œå›¾æ–‡çš„cross attnï¼Œæœ€åæ–‡æœ¬è¾“å‡ºæ–‡æ–‡å’Œæ–‡å›¾çš„å¹³å‡ï¼Œå›¾ç‰‡è¾“å‡ºå›¾å›¾å’Œå›¾æ–‡çš„å¹³å‡
    2ï¼‰ text is None: layer3ä»¥åï¼Œå›¾åƒå’Œæ–‡æœ¬tokenå·²è¢«æ‹¼æ¥æˆä¸€ä¸ªåºåˆ—ï¼Œåªæœ‰ä¸€ä¸ªhidden_statesè¾“å…¥
        æ ‡å‡†self attn



å›¾åƒonlyï¼Œæ–‡æœ¬onlyï¼Œå›¾åƒ+æ–‡æœ¬

1. config.py
config.modality.use_image = True/False
config.modality.use_text = True/False
config.modality.mode = 'image'/'text'/'multimodal'

2. embedding [â†’](embed.py)
if self.use_image:
    self.patch_embeddings = Conv2d(...)  # å›¾åƒpatchåµŒå…¥
    self.position_embeddings = nn.Parameter(...)  # å›¾åƒä½ç½®ç¼–ç 
    self.cls_token = nn.Parameter(...)  # å›¾åƒCLS token
 
if self.use_text:
    self.cc_embeddings = Linear(...)
    self.lab_embeddings = Linear(...)
    self.sex_embeddings = Linear(...)
    self.age_embeddings = Linear(...)

3. encoder [â†’](encoder.py)
åœ¨Encoder.__init__()ä¸­
for i in range(config.transformer["num_layers"]):
    åªæœ‰å¤šæ¨¡æ€æ¨¡å¼å‰2å±‚æ‰ç”¨å¤šæ¨¡æ€æ³¨æ„åŠ›
    if i < 2 and self.use_image and self.use_text:
        layer = Block(config, vis, mm=True)  # å¤šæ¨¡æ€Block
    else:
        layer = Block(config, vis, mm=False)  # æ ‡å‡†Block

åœ¨Transformer.forward()ä¸­
if self.use_image and self.use_text:
    # å¤šæ¨¡æ€
    primary_embeddings = image_embeddings
    auxiliary_embeddings = text_embeddings
elif self.use_image:
    # çº¯å›¾åƒ
    primary_embeddings = image_embeddings
    auxiliary_embeddings = None
elif self.use_text:
    # çº¯æ–‡æœ¬
    primary_embeddings = text_embeddings
    auxiliary_embeddings = None

### è¿™äº›å‚æ•°åœ¨ä¸‰ç§æ¨¡æ€ä¸‹éƒ½æ˜¯ç›¸åŒçš„
self.transformer.encoder.encoder_norm  # âœ… å…±äº«
self.head  # âœ… å…±äº«
self.transformer.encoder.layer[3-11]  # âœ… å…±äº«

### è¿™äº›å‚æ•°æ˜¯æ¨¡æ€ç‰¹å®šçš„
self.transformer.embeddings.patch_embeddings  # ğŸ”¸ ä»…å›¾åƒæ¨¡æ€
self.transformer.embeddings.cc_embeddings     # ğŸ”¸ ä»…æ–‡æœ¬æ¨¡æ€
self.transformer.encoder.layer[0-1]  # ğŸ”¸ å¤šæ¨¡æ€æ³¨æ„åŠ›